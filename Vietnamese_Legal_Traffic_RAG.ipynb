{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNfSlQyVjJ6d+wex0fXAv2M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02c6313896d34a97a4817d8d477ce188": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_688a441a111241e1aa1177c4c704267a",
              "IPY_MODEL_968797820c2d45f4b709214142ba8c98",
              "IPY_MODEL_9a1a2e79a42d4d1aa07b5ae3f4a11d71"
            ],
            "layout": "IPY_MODEL_8ff7b45ddcd641f7862e8c385e9eb843"
          }
        },
        "688a441a111241e1aa1177c4c704267a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6344668ba9214c96a1abe18e0582844a",
            "placeholder": "​",
            "style": "IPY_MODEL_63d4935922ba4c339950a80331497c8e",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "968797820c2d45f4b709214142ba8c98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_968fd8cabbe54e28a502f5f7b0e1be31",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4beb3c70d3b94ea09d1c95c2704bab89",
            "value": 8
          }
        },
        "9a1a2e79a42d4d1aa07b5ae3f4a11d71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2415ff77368843faad778b137ca0e7be",
            "placeholder": "​",
            "style": "IPY_MODEL_58eb3ce6e1b24eca99eca00e6df21159",
            "value": " 8/8 [01:23&lt;00:00,  9.48s/it]"
          }
        },
        "8ff7b45ddcd641f7862e8c385e9eb843": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6344668ba9214c96a1abe18e0582844a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63d4935922ba4c339950a80331497c8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "968fd8cabbe54e28a502f5f7b0e1be31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4beb3c70d3b94ea09d1c95c2704bab89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2415ff77368843faad778b137ca0e7be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58eb3ce6e1b24eca99eca00e6df21159": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nguyenfan20/AI-Agents-using-LangChain/blob/main/Vietnamese_Legal_Traffic_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tổng quan dự án 🤖"
      ],
      "metadata": {
        "id": "If8uKmFJb7WP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notebook này trình bày cách tạo một chatbot bằng hệ thống RAG dựa vào thư viện LangChain và LLMs"
      ],
      "metadata": {
        "id": "C2YLtB01cSR-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6fB8o1BHxf1",
        "outputId": "ab09233c-8e1e-4e24-9c0b-4bb3e71fc68e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: fsspec 2024.12.0\n",
            "Uninstalling fsspec-2024.12.0:\n",
            "  Successfully uninstalled fsspec-2024.12.0\n",
            "Found existing installation: datasets 3.5.0\n",
            "Uninstalling datasets-3.5.0:\n",
            "  Successfully uninstalled datasets-3.5.0\n",
            "Found existing installation: gcsfs 2024.12.0\n",
            "Uninstalling gcsfs-2024.12.0:\n",
            "  Successfully uninstalled gcsfs-2024.12.0\n",
            "Collecting fsspec==2024.12.0\n",
            "  Using cached fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting datasets==3.5.0\n",
            "  Using cached datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting gcsfs==2024.12.0\n",
            "  Using cached gcsfs-2024.12.0-py2.py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (3.11.14)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (0.29.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (6.0.2)\n",
            "Requirement already satisfied: decorator>4.1.2 in /usr/local/lib/python3.11/dist-packages (from gcsfs==2024.12.0) (4.4.2)\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.11/dist-packages (from gcsfs==2024.12.0) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.11/dist-packages (from gcsfs==2024.12.0) (1.2.1)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.11/dist-packages (from gcsfs==2024.12.0) (2.19.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0) (1.18.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.2->gcsfs==2024.12.0) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.2->gcsfs==2024.12.0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.2->gcsfs==2024.12.0) (4.9)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets==3.5.0) (4.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.5.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.5.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.5.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.5.0) (2025.1.31)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib->gcsfs==2024.12.0) (2.0.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs==2024.12.0) (2.24.2)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs==2024.12.0) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs==2024.12.0) (2.7.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs==2024.12.0) (1.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.5.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.5.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.5.0) (2025.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs==2024.12.0) (1.69.2)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs==2024.12.0) (5.29.4)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs==2024.12.0) (1.26.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs==2024.12.0) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==3.5.0) (1.17.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs==2024.12.0) (3.2.2)\n",
            "Using cached fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "Using cached datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "Using cached gcsfs-2024.12.0-py2.py3-none-any.whl (35 kB)\n",
            "Installing collected packages: fsspec, datasets, gcsfs\n",
            "Successfully installed datasets-3.5.0 fsspec-2024.12.0 gcsfs-2024.12.0\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y fsspec datasets gcsfs\n",
        "!pip install fsspec==2024.12.0 datasets==3.5.0 gcsfs==2024.12.0\n",
        "!pip install -q torch transformers accelerate bitsandbytes \\\n",
        "  langchain sentence-transformers faiss-cpu openpyxl pacmap datasets \\\n",
        "  langchain-community ragatouille tqdm pymupdf python-docx pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tqdm.notebook import tqdm\n",
        "import pandas as pd\n",
        "from typing import Optional, List, Tuple\n",
        "\n",
        "FILE_01 = '/content/luatgt2.pdf'\n",
        "\n",
        "\n",
        "VECTOR_DATABASE_PATH = '/content/vectordatabase'\n",
        "os.makedirs('/content/vectordatabase', exist_ok=True)"
      ],
      "metadata": {
        "id": "tDm7mOE_H7Xh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chunking 🔪"
      ],
      "metadata": {
        "id": "tRbi5bd0sjjf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.docstore.document import Document as LangchainDocument\n",
        "from tqdm import tqdm\n",
        "from langchain.document_loaders import PyMuPDFLoader\n",
        "from docx import Document as DocxDocument\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def load_pdf_file(file_path):\n",
        "    \"\"\"Loads a PDF file and returns its entire content using PyMuPDFLoader.\"\"\"\n",
        "    loader = PyMuPDFLoader(file_path)\n",
        "    documents = loader.load()\n",
        "    full_content = \"\"\n",
        "    for doc in documents:\n",
        "        full_content += doc.page_content + \"\\n\"  # Add a newline to separate pages\n",
        "    return full_content  # Return the entire content\n",
        "\n",
        "def load_txt_file(file_path):\n",
        "    \"\"\"Loads a TXT file and returns its content as a string.\"\"\"\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        return file.read()\n",
        "\n",
        "def load_docx_file(file_path):\n",
        "    \"\"\"Loads a DOCX file and returns its content as a string.\"\"\"\n",
        "    doc = DocxDocument(file_path)\n",
        "    full_text = []\n",
        "    for para in doc.paragraphs:\n",
        "        full_text.append(para.text)\n",
        "    return \"\\n\".join(full_text)\n",
        "\n",
        "def load_csv_file(file_path):\n",
        "    \"\"\"Loads a CSV file and concatenates all rows as a single string.\"\"\"\n",
        "    df = pd.read_csv(file_path)\n",
        "    return df.to_string(index=False)  # Converts the DataFrame to a string (without row indices)\n",
        "\n",
        "def load_file(file_path):\n",
        "    \"\"\"Determines the file type and loads the file content.\"\"\"\n",
        "    ext = os.path.splitext(file_path)[1].lower()\n",
        "    if ext == '.txt':\n",
        "        return load_txt_file(file_path)\n",
        "    elif ext in ['.doc', '.docx']:\n",
        "        return load_docx_file(file_path)\n",
        "    elif ext == '.pdf':\n",
        "        return load_pdf_file(file_path)\n",
        "    elif ext == '.csv':\n",
        "        return load_csv_file(file_path)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported file type: {ext}\")"
      ],
      "metadata": {
        "id": "A1B1p27JLJ1P"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of document file paths (PDF, DOCX, TXT, CSV)\n",
        "file_paths = [FILE_01] # Example file paths. It can be like: file_paths = [FILE_01, FILE_02,..]\n",
        "\n",
        "RAW_KNOWLEDGE_BASE = []\n",
        "for file_path in tqdm(file_paths):\n",
        "    try:\n",
        "        content = load_file(file_path)\n",
        "        RAW_KNOWLEDGE_BASE.append(\n",
        "            LangchainDocument(page_content=content, metadata={\"source\": file_path})\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to process {file_path}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzuAON3ELhlo",
        "outputId": "6c0f97e4-af3a-462f-8729-cf49aa017131"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:01<00:00,  1.07s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for doc in RAW_KNOWLEDGE_BASE:\n",
        "    print(f\"Source: {doc.metadata['source']}\")\n",
        "    print(f\"Content snippet: {doc.page_content[:500]}...\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mOxisvoLnZP",
        "outputId": "11ca4edf-4fe9-429f-a07c-3a7f660b0aaa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source: /content/luatgt2.pdf\n",
            "Content snippet: CHÍNH PHỦ\n",
            "--------\n",
            "CỘNG HÒA XÃ HỘI CHỦNGHĨA VIỆT NAM\n",
            "Độc lập - Tựdo - Hạnh phúc\n",
            "---------------\n",
            "Số: 168/2024/NĐ-CP\n",
            "Hà Nội, ngày 26 tháng 12 năm 2024\n",
            "NGHỊĐỊNH\n",
            "QUY ĐỊNH XỬPHẠT VI PHẠM HÀNH CHÍNH VỀTRẬT TỰ, AN TOÀN GIAO\n",
            "THÔNG TRONG LĨNH VỰC GIAO THÔNG ĐƯỜNG BỘ; TRỪĐIỂM, PHỤC HỒI\n",
            "ĐIỂM GIẤY PHÉP LÁI XE\n",
            "Căn cứLuật Tổchức Chính phủngày 19 tháng 6 năm 2015; Luật sửa đổi, bổsung một\n",
            "sốđiều của Luật Tổchức Chính phủvà Luật Tổchức chính quyền địa phương ngày 22\n",
            "tháng 11 năm 2019;\n",
            "Căn cứLuật Xửlý vi phạm hà...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# We use a hierarchical list of separators specifically tailored for splitting Markdown documents\n",
        "# This list is taken from LangChain's MarkdownTextSplitter class\n",
        "MARKDOWN_SEPARATORS = [\n",
        "    \"\\n#{1,6} \",\n",
        "    \"```\\n\",\n",
        "    \"\\n\\\\*\\\\*\\\\*+\\n\",\n",
        "    \"\\n---+\\n\",\n",
        "    \"\\n___+\\n\",\n",
        "    \"\\n\\n\",\n",
        "    \"\\n\",\n",
        "    \" \",\n",
        "    \"\",\n",
        "]\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,  # The maximum number of characters in a chunk: we selected this value arbitrarily\n",
        "    chunk_overlap=100,  # The number of characters to overlap between chunks\n",
        "    add_start_index=True,  # If `True`, includes chunk's start index in metadata\n",
        "    strip_whitespace=True,  # If `True`, strips whitespace from the start and end of every document\n",
        "    separators=MARKDOWN_SEPARATORS,\n",
        ")\n",
        "\n",
        "docs_processed = []\n",
        "for doc in RAW_KNOWLEDGE_BASE:\n",
        "    docs_processed += text_splitter.split_documents([doc])"
      ],
      "metadata": {
        "id": "XU34rNVHLrDP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# To get the value of the max sequence_length, we will query the underlying `SentenceTransformer` object used in the RecursiveCharacterTextSplitter\n",
        "print(\n",
        "    f\"Model's maximum sequence length: {SentenceTransformer('minhtt/phobert-base-v2').max_seq_length}\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "palqBVZRLw06",
        "outputId": "1c0aa37a-8c59-40d4-e07e-208956bf437b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name minhtt/phobert-base-v2. Creating a new one with mean pooling.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at minhtt/phobert-base-v2 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model's maximum sequence length: 258\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding document 📂"
      ],
      "metadata": {
        "id": "SXsfngHhuDnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "EMBEDDING_MODEL_NAME = \"AITeamVN/Vietnamese_Embedding\"\n",
        "\n",
        "\n",
        "def split_documents(\n",
        "    chunk_size: int,\n",
        "    knowledge_base: List[LangchainDocument],\n",
        "    tokenizer_name: Optional[str] = EMBEDDING_MODEL_NAME,\n",
        ") -> List[LangchainDocument]:\n",
        "    \"\"\"\n",
        "    Split documents into chunks of maximum size `chunk_size` tokens and return a list of documents.\n",
        "    \"\"\"\n",
        "    text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
        "        AutoTokenizer.from_pretrained(tokenizer_name),\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=int(chunk_size / 10),\n",
        "        add_start_index=True,\n",
        "        strip_whitespace=True,\n",
        "        separators=MARKDOWN_SEPARATORS,\n",
        "    )\n",
        "\n",
        "    docs_processed = []\n",
        "    for doc in knowledge_base:\n",
        "        docs_processed += text_splitter.split_documents([doc])\n",
        "\n",
        "    # Remove duplicates\n",
        "    unique_texts = {}\n",
        "    docs_processed_unique = []\n",
        "    for doc in docs_processed:\n",
        "        if doc.page_content not in unique_texts:\n",
        "            unique_texts[doc.page_content] = True\n",
        "            docs_processed_unique.append(doc)\n",
        "\n",
        "    return docs_processed_unique\n",
        "\n",
        "\n",
        "docs_processed = split_documents(\n",
        "    258,  # We choose a chunk size adapted to our model\n",
        "    RAW_KNOWLEDGE_BASE,\n",
        "    tokenizer_name=EMBEDDING_MODEL_NAME,\n",
        ")"
      ],
      "metadata": {
        "id": "h9SqYZjLL1fl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vector Database 📂"
      ],
      "metadata": {
        "id": "KJ8b7xebvXrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores.utils import DistanceStrategy\n",
        "\n",
        "embedding_model = HuggingFaceEmbeddings(\n",
        "    model_name=EMBEDDING_MODEL_NAME,\n",
        "    multi_process=True,\n",
        "    model_kwargs={\"device\": \"cuda\"},\n",
        "    encode_kwargs={\"normalize_embeddings\": True},  # Set `True` for cosine similarity\n",
        ")\n",
        "\n",
        "KNOWLEDGE_VECTOR_DATABASE = FAISS.from_documents(\n",
        "    docs_processed, embedding_model, distance_strategy=DistanceStrategy.COSINE\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2sMpEQtMKzL",
        "outputId": "7de18eb1-9ace-4241-e70a-20055ea995a1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-26065c6d9089>:6: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embedding_model = HuggingFaceEmbeddings(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lưu Vector Database được xử lý vào các thư mục"
      ],
      "metadata": {
        "id": "EuGgwbRvwgeJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss  # Make sure to import FAISS\n",
        "import pickle\n",
        "\n",
        "# Save the FAISS index to a file\n",
        "faiss_file_path = os.path.join(VECTOR_DATABASE_PATH, 'faiss_index.bin')\n",
        "faiss.write_index(KNOWLEDGE_VECTOR_DATABASE.index, faiss_file_path)\n",
        "print(f\"FAISS index saved to {faiss_file_path}\")\n",
        "\n",
        "# Save the document store to a pickle file\n",
        "docstore_file_path = os.path.join(VECTOR_DATABASE_PATH, 'docstore.pkl')\n",
        "with open(docstore_file_path, 'wb') as f:\n",
        "    pickle.dump(KNOWLEDGE_VECTOR_DATABASE.docstore, f)\n",
        "print(f\"Document store saved to {docstore_file_path}\")\n",
        "\n",
        "# Save the index_to_docstore_id mapping\n",
        "mapping_file_path = os.path.join(VECTOR_DATABASE_PATH, 'index_to_docstore_id.pkl')\n",
        "with open(mapping_file_path, 'wb') as f:\n",
        "    pickle.dump(KNOWLEDGE_VECTOR_DATABASE.index_to_docstore_id, f)\n",
        "print(f\"Index to document store ID mapping saved to {mapping_file_path}\")\n",
        "\n",
        "# Load the FAISS index from the file\n",
        "loaded_index = faiss.read_index(faiss_file_path)\n",
        "\n",
        "# Load the document store from the pickle file\n",
        "with open(docstore_file_path, 'rb') as f:\n",
        "    loaded_docstore = pickle.load(f)\n",
        "\n",
        "# Load the index_to_docstore_id mapping\n",
        "with open(mapping_file_path, 'rb') as f:\n",
        "    index_to_docstore_id = pickle.load(f)\n",
        "\n",
        "# Create the FAISS vector store using the loaded index and document store\n",
        "loaded_vector_database = FAISS(\n",
        "    index=loaded_index,\n",
        "    docstore=loaded_docstore,\n",
        "    index_to_docstore_id=index_to_docstore_id,\n",
        "    embedding_function=embedding_model.embed_query\n",
        ")\n",
        "print(\"Vector database loaded successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehKDq37DMfrt",
        "outputId": "de73b0ce-684b-4d82-c5fc-e65d7937014b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.vectorstores.faiss:`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAISS index saved to /content/vectordatabase/faiss_index.bin\n",
            "Document store saved to /content/vectordatabase/docstore.pkl\n",
            "Index to document store ID mapping saved to /content/vectordatabase/index_to_docstore_id.pkl\n",
            "Vector database loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chain với thư mục đã lưu"
      ],
      "metadata": {
        "id": "qcRAMGk7wwjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Embed a user query in the same space\n",
        "user_query = \"Quy định về độ tuổi lái xe mô tô hai bánh?\"\n",
        "query_vector = embedding_model.embed_query(user_query)"
      ],
      "metadata": {
        "id": "x72vDcblMr4w"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\nStarting retrieval for {user_query=}...\")\n",
        "# retrieved_docs = KNOWLEDGE_VECTOR_DATABASE.similarity_search(query=user_query, k=5)\n",
        "\n",
        "retrieved_docs = loaded_vector_database.similarity_search(query=user_query, k=5)\n",
        "\n",
        "print(\n",
        "    \"\\n==================================Top document==================================\"\n",
        ")\n",
        "print(retrieved_docs[0].page_content)\n",
        "print(\"==================================Metadata==================================\")\n",
        "print(retrieved_docs[0].metadata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tVUVC5_M6B6",
        "outputId": "12447393-fe9e-4f65-ba1f-cfb2713be60d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting retrieval for user_query='Quy định về độ tuổi lái xe mô tô hai bánh?'...\n",
            "\n",
            "==================================Top document==================================\n",
            "xe).\n",
            "6. Phạt tiền từ4.000.000 đồng đến 6.000.000 đồng đối với người từđủ16 tuổi đến dưới\n",
            "18 tuổi điều khiển xe ô tô, xe chởngười bốn bánh có gắn động cơ, xe chởhàng bốn bánh\n",
            "có gắn động cơ và các loại xe tương tựxe ô tô.\n",
            "7. Phạt tiền từ6.000.000 đồng đến 8.000.000 đồng đối với người điều khiển xe mô tô hai\n",
            "bánh có dung tích xi-lanh trên 125 cm3 trởlên hoặc có công suất động cơ điện trên 11\n",
            "kW, xe mô tô ba bánh thực hiện một trong các hành vi vi phạm sau đây:\n",
            "a) Có giấy phép lái xe nhưng không phù hợp với loại xe đang điều khiển;\n",
            "b) Không có giấy phép lái xe hoặc sửdụng giấy phép lái xe đã bịtrừhết điểm, giấy phép\n",
            "lái xe không do cơ quan có thẩm quyền cấp, giấy phép lái xe bịtẩy xóa, giấy phép lái xe\n",
            "không còn hiệu lực;\n",
            "==================================Metadata==================================\n",
            "{'source': '/content/luatgt2.pdf', 'start_index': 99836}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Đưa LLM để tạo sinh câu trả lời với đữ liệu được chain"
      ],
      "metadata": {
        "id": "cEvU27LIxcTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "READER_MODEL_NAME = \"HuggingFaceH4/zephyr-7b-beta\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        ")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    READER_MODEL_NAME, quantization_config=bnb_config\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(READER_MODEL_NAME)\n",
        "\n",
        "READER_LLM = pipeline(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    task=\"text-generation\",\n",
        "    do_sample=True,\n",
        "    temperature=0.2,\n",
        "    repetition_penalty=1.1,\n",
        "    return_full_text=False,\n",
        "    max_new_tokens=500,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "02c6313896d34a97a4817d8d477ce188",
            "688a441a111241e1aa1177c4c704267a",
            "968797820c2d45f4b709214142ba8c98",
            "9a1a2e79a42d4d1aa07b5ae3f4a11d71",
            "8ff7b45ddcd641f7862e8c385e9eb843",
            "6344668ba9214c96a1abe18e0582844a",
            "63d4935922ba4c339950a80331497c8e",
            "968fd8cabbe54e28a502f5f7b0e1be31",
            "4beb3c70d3b94ea09d1c95c2704bab89",
            "2415ff77368843faad778b137ca0e7be",
            "58eb3ce6e1b24eca99eca00e6df21159"
          ]
        },
        "id": "ZIju0plfNAjW",
        "outputId": "6f0029fb-246d-4a11-fe0f-c6c4f1db4170"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "02c6313896d34a97a4817d8d477ce188"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install langdetect"
      ],
      "metadata": {
        "id": "8du24nceNRgB"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langdetect import detect\n",
        "\n",
        "prompt_in_chat_format_en = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"\"\"Using the information contained in the context,\n",
        "give a comprehensive answer to the question.\n",
        "Respond only to the question asked, response should be concise and relevant to the question.\n",
        "Provide the number of the source document when relevant.\n",
        "If the answer cannot be deduced from the context, do not give an answer.\"\"\",\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"\"\"Context:\n",
        "{context}\n",
        "---\n",
        "Now here is the question you need to answer.\n",
        "\n",
        "Question: {question}\"\"\",\n",
        "    },\n",
        "]\n",
        "\n",
        "# Prompt template for Vietnamese\n",
        "prompt_in_chat_format_vi = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"\"\"Sử dụng thông tin trong ngữ cảnh, hãy đưa ra câu trả lời đầy đủ cho câu hỏi.\n",
        "Chỉ trả lời câu hỏi được hỏi, câu trả lời cần ngắn gọn và phù hợp với câu hỏi.\n",
        "Cung cấp số của tài liệu nguồn khi phù hợp.\n",
        "Nếu câu trả lời không thể suy ra từ ngữ cảnh, không đưa ra câu trả lời.\"\"\",\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"\"\"Ngữ cảnh:\n",
        "{context}\n",
        "---\n",
        "Bây giờ đây là câu hỏi mà bạn cần trả lời.\n",
        "\n",
        "Câu hỏi: {question}\"\"\",\n",
        "    },\n",
        "]\n",
        "\n",
        "def detect_language(query):\n",
        "    return detect(query)\n",
        "\n",
        "def create_prompt(question):\n",
        "\n",
        "    language = detect_language(question)\n",
        "\n",
        "    if language == 'vi':\n",
        "        RAG_PROMPT_TEMPLATE = tokenizer.apply_chat_template(\n",
        "            prompt_in_chat_format_vi, tokenize=False, add_generation_prompt=True\n",
        "        )\n",
        "    else:\n",
        "        RAG_PROMPT_TEMPLATE = tokenizer.apply_chat_template(\n",
        "            prompt_in_chat_format_en, tokenize=False, add_generation_prompt=True\n",
        "        )\n",
        "\n",
        "    return RAG_PROMPT_TEMPLATE\n",
        "\n",
        "#test prompt if the question is Vietnamese\n",
        "\n",
        "test_prompt = create_prompt(\"Hà Nội là thủ đô của nước nào?\")\n",
        "print(test_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-XNwX-iOBcP",
        "outputId": "cc42018b-9f80-40f0-b15c-2fd4b2015cbd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|system|>\n",
            "Sử dụng thông tin trong ngữ cảnh, hãy đưa ra câu trả lời đầy đủ cho câu hỏi.\n",
            "Chỉ trả lời câu hỏi được hỏi, câu trả lời cần ngắn gọn và phù hợp với câu hỏi.\n",
            "Cung cấp số của tài liệu nguồn khi phù hợp.\n",
            "Nếu câu trả lời không thể suy ra từ ngữ cảnh, không đưa ra câu trả lời.</s>\n",
            "<|user|>\n",
            "Ngữ cảnh:\n",
            "{context}\n",
            "---\n",
            "Bây giờ đây là câu hỏi mà bạn cần trả lời.\n",
            "\n",
            "Câu hỏi: {question}</s>\n",
            "<|assistant|>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retrieved_docs_text = [\n",
        "    doc.page_content for doc in retrieved_docs\n",
        "]  # We only need the text of the documents\n",
        "context = \"\\nExtracted documents:\\n\"\n",
        "context += \"\".join(\n",
        "    [f\"Document {str(i)}:::\\n\" + doc for i, doc in enumerate(retrieved_docs_text)]\n",
        ")\n",
        "\n",
        "user_query=\"Quy định về độ tuổi lái xe mô tô 2 bánh?\"\n",
        "\n",
        "rag_prompt = create_prompt(user_query)\n",
        "final_prompt = rag_prompt.format(\n",
        "    question=user_query, context=context\n",
        ")\n",
        "\n",
        "# Redact an answer\n",
        "answer = READER_LLM(final_prompt)[0][\"generated_text\"]\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhkV9GeSOMxi",
        "outputId": "3130f863-8360-4e39-afc6-94cd7162c0d2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Theo quy định, người lái xe mô tô hai bánh phải được tuổi 16 hoặc trở lên. (Điều 18, Document 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Pipeline\n",
        "from typing import Tuple, List\n",
        "from langchain.schema import Document as LangchainDocument\n",
        "from faiss import Index as FAISS\n",
        "\n",
        "def answer_with_rag(\n",
        "    question: str,\n",
        "    llm: Pipeline,\n",
        "    knowledge_index: FAISS,\n",
        "    num_retrieved_docs: int = 30,\n",
        "    num_docs_final: int = 5,\n",
        ") -> Tuple[str, List[LangchainDocument]]:\n",
        "\n",
        "    # Gather documents with retriever\n",
        "    print(\"=> Retrieving documents...\")\n",
        "    relevant_docs = knowledge_index.similarity_search(\n",
        "        query=question, k=num_retrieved_docs\n",
        "    )\n",
        "\n",
        "    # Ensure that relevant_docs is not empty or None\n",
        "    if not relevant_docs:\n",
        "        raise ValueError(\"No relevant documents retrieved.\")\n",
        "\n",
        "    # Keep only the text from the retrieved documents\n",
        "    relevant_docs = [doc.page_content for doc in relevant_docs]\n",
        "\n",
        "    # Ensure k is not larger than the number of documents\n",
        "    num_docs_final = min(num_docs_final, len(relevant_docs))\n",
        "\n",
        "    if num_docs_final < 1:\n",
        "        raise ValueError(\"Not enough documents for processing.\")\n",
        "\n",
        "    # Limit to the final number of documents\n",
        "    relevant_docs = relevant_docs[:num_docs_final]\n",
        "\n",
        "    # Build the final prompt\n",
        "    context = \"\\nExtracted documents:\\n\"\n",
        "    context += \"\".join(\n",
        "        [f\"Document {str(i)}:::\\n\" + doc for i, doc in enumerate(relevant_docs)]\n",
        "    )\n",
        "\n",
        "    RAG_PROMPT_TEMPLATE = create_prompt(question)\n",
        "    final_prompt = RAG_PROMPT_TEMPLATE.format(question=question, context=context)\n",
        "\n",
        "    # Generate the answer using the LLM\n",
        "    print(\"=> Generating answer...\")\n",
        "    answer = llm(final_prompt)[0][\"generated_text\"]\n",
        "\n",
        "    return answer, relevant_docs"
      ],
      "metadata": {
        "id": "CqoSJDAEORYK"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Quy định về mức phạt với vi phạm nồng độ cồn trong máu?\"\n",
        "\n",
        "answer, relevant_docs = answer_with_rag(\n",
        "    question, READER_LLM, loaded_vector_database)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HBvtBwSP-gd",
        "outputId": "58cd2cb0-9e78-40ce-cae9-02c8184072fc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Retrieving documents...\n",
            "=> Generating answer...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"==================================Answer==================================\")\n",
        "print(f\"{answer}\")\n",
        "print(\"==================================Source docs==================================\")\n",
        "for i, doc in enumerate(relevant_docs):\n",
        "    print(f\"Document {i}------------------------------------------------------------\")\n",
        "    print(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaj6DxnGQi4_",
        "outputId": "f80f443a-a836-4bde-e782-2e6abbb0e9b4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================Answer==================================\n",
            "Quy định về mức phạt với vi phạm nồng độcồn trong máu được điều chỉnh trong các trường hợp sau:\n",
            "\n",
            "- Document 1: Nồng độcồn nhưng chưa vượt quá 50 miligam/100 mililít máu hoặc chưa vượt quá 0,25 miligam/1 lít khí thở (Điều kháu a trong các hành vi vi phạm): Phạt tiền từ 12.000.000 đồng đến 14.000.000 đồng.\n",
            "\n",
            "- Document 2: Nồng độcồn vượt quá 80 miligam/100 mililít máu (Điều kháu a trong các hành vi vi phạm): Phạt tiền từ 18.000.000 đồng đến 20.000.000 đồng.\n",
            "\n",
            "- Document 3: Khi có liên quan trực tiếp đến vụ ta nạn giao thông, không dừng ngay phương tiện, không giữnguyên hiện trường, không trợgiúp người bị nạn (Điều kháu a trong các hành vi vi phạm): Phạt tiền theo quy định tại điểm c khoản 9 Điều này.\n",
            "\n",
            "Các quy định trên có hiệu lực chính quyền nếu người điều khiển xe\n",
            "==================================Source docs==================================\n",
            "Document 0------------------------------------------------------------\n",
            "hoặc đi vào đường có biển báo hiệu có nội dung cấm đi vào đối với loại phương tiện đang\n",
            "điều khiển gây tai nạn giao thông, trừcác hành vi vi phạm quy định tại điểm đ khoản 11\n",
            "Điều này;\n",
            "b) Vi phạm quy định tại một trong các điểm, khoản sau của Điều này mà gây tai nạn giao\n",
            "thông: điểm a, điểm b, điểm c, điểm d, điểm đ khoản 1; điểm c khoản 2; điểm b, điểm g,\n",
            "điểm h, điểm n, điểm o, điểm p, khoản 3; điểm a, điểm c, điểm d khoản 4; điểm c, điểm d,\n",
            "điểm e, điểm h, điểm n, điểm o, điểm q khoản 5; điểm b khoản 7; điểm b, điểm c, điểm d\n",
            "khoản 9 Điều này.\n",
            "11. Phạt tiền từ30.000.000 đồng đến 40.000.000 đồng đối với người điều khiển xe thực\n",
            "hiện một trong các hành vi vi phạm sau đây:\n",
            "a) Điều khiển xe trên đường mà trong máu hoặc hơi thởcó nồng độcồn vượt quá 80\n",
            "Document 1------------------------------------------------------------\n",
            "a) Điều khiển xe chạy quá tốc độquy định trên 20 km/h đến 35 km/h;\n",
            "b) Không nhường đường hoặc gây cản trởxe được quyền ưu tiên đang phát tín hiệu ưu\n",
            "tiên đi làm nhiệm vụ;\n",
            "c) Điều khiển xe trên đường mà trong máu hoặc hơi thởcó nồng độcồn nhưng chưa vượt\n",
            "quá 50 miligam/100 mililít máu hoặc chưa vượt quá 0,25 miligam/1 lít khí thở;\n",
            "d) Điều khiển xe đi trên vỉa hè, trừtrường hợp điều khiển xe đi qua vỉa hè đểvào nhà, cơ\n",
            "quan.\n",
            "7. Phạt tiền từ12.000.000 đồng đến 14.000.000 đồng đối với người điều khiển xe thực\n",
            "hiện một trong các hành vi vi phạm sau đây:\n",
            "a) Điều khiển xe chạy quá tốc độquy định trên 35 km/h;\n",
            "b) Điều khiển xe chởngười bốn bánh có gắn động cơ, xe chởhàng bốn bánh có gắn động\n",
            "cơ đi vào đường cao tốc;\n",
            "Document 2------------------------------------------------------------\n",
            "cơ quan công an, Ủy ban nhân dân nơi gần nhất;\n",
            "d) Vi phạm quy định tại một trong các điểm, khoản sau của Điều này mà gây tai nạn giao\n",
            "thông: điểm a, điểm b khoản 1; điểm d khoản 2; điểm b, điểm c, điểm d, điểm đ khoản 3;\n",
            "điểm b khoản 4; điểm b khoản 5; điểm e, điểm g, điểm i khoản 6; điểm b, điểm c khoản 7\n",
            "Điều này.\n",
            "9. Phạt tiền từ18.000.000 đồng đến 20.000.000 đồng đối với người điều khiển xe thực\n",
            "hiện một trong các hành vi vi phạm sau đây:\n",
            "a) Điều khiển xe trên đường mà trong máu hoặc hơi thởcó nồng độcồn vượt quá 80\n",
            "miligam/100 mililít máu hoặc vượt quá 0,4 miligam/1 lít khí thở;\n",
            "b) Không chấp hành yêu cầu kiểm tra vềnồng độcồn của người thi hành công vụ;\n",
            "c) Điều khiển xe trên đường mà trong cơ thểcó chất ma túy hoặc chất kích thích khác mà\n",
            "Document 3------------------------------------------------------------\n",
            "a) Điều khiển xe có liên quan trực tiếp đến vụtai nạn giao thông mà không dừng ngay\n",
            "phương tiện, không giữnguyên hiện trường, không trợgiúp người bịnạn, trừhành vi vi\n",
            "phạm quy định tại điểm c khoản 9 Điều này;\n",
            "b) Chuyển hướng không nhường quyền đi trước cho: người đi bộ, xe lăn của người\n",
            "khuyết tật qua đường tại nơi có vạch kẻđường dành cho người đi bộ; xe thô sơ đang đi\n",
            "trên phần đường dành cho xe thô sơ;\n",
            "c) Chuyển hướng không nhường đường cho: các xe đi ngược chiều; người đi bộ, xe thô\n",
            "sơ đang qua đường tại nơi không có vạch kẻđường cho người đi bộ.\n",
            "6. Phạt tiền từ2.000.000 đồng đến 3.000.000 đồng đối với người điều khiển xe thực hiện\n",
            "một trong các hành vi vi phạm sau đây:\n",
            "a) Điều khiển xe trên đường mà trong máu hoặc hơi thởcó nồng độcồn nhưng chưa vượt\n",
            "Document 4------------------------------------------------------------\n",
            "kiểm soát giao thông;\n",
            "đ) Không nhường đường hoặc gây cản trởxe được quyền ưu tiên đang phát tín hiệu ưu\n",
            "tiên đi làm nhiệm vụ.\n",
            "8. Phạt tiền từ6.000.000 đồng đến 8.000.000 đồng đối với người điều khiển xe thực hiện\n",
            "một trong các hành vi vi phạm sau đây:\n",
            "a) Điều khiển xe chạy quá tốc độquy định trên 20 km/h;\n",
            "b) Điều khiển xe trên đường mà trong máu hoặc hơi thởcó nồng độcồn vượt quá 50\n",
            "miligam đến 80 miligam/100 mililít máu hoặc vượt quá 0,25 miligam đến 0,4 miligam/1\n",
            "lít khí thở.\n",
            "9. Phạt tiền từ8.000.000 đồng đến 10.000.000 đồng đối với người điều khiển xe thực\n",
            "hiện một trong các hành vi vi phạm sau đây:\n",
            "a) Điều khiển xe lạng lách, đánh võng trên đường bộ; sửdụng chân chống hoặc vật khác\n",
            "quệt xuống đường khi xe đang chạy;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os._exit(00)"
      ],
      "metadata": {
        "id": "h88W3dqXTVPV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}