{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpZCvB86k8Wj",
        "outputId": "692e522d-d7e9-4225-b837-8742ea6684f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.20)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.4)\n",
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.11/dist-packages (2.0.10)\n",
            "Collecting langchain-google-genai\n",
            "  Using cached langchain_google_genai-2.0.11-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.41 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.43)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.13)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.160.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.25.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.0)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "INFO: pip is looking at multiple versions of langchain-google-genai to determine which version is compatible with other requirements. This could take a while.\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.69.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (24.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain) (3.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade langchain google-generativeai langchain-google-genai python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8Z_xsEzBgxV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"GOOGLE_GENERATIVE_API_KEY\"] = \"your_API_KEY\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "ZkGXdKJEWhRb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "GOOGLE_GENERATIVE_API_KEY = os.getenv(\"GOOGLE_GENERATIVE_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Ppxhv40AXSW1"
      },
      "outputs": [],
      "source": [
        "class Calculator:\n",
        "    def calculate(self, expression: str) -> str:\n",
        "        try:\n",
        "            # Sử dụng eval một cách hạn chế built-in để tính toán biểu thức\n",
        "            result = eval(expression, {\"__builtins__\": None}, {})\n",
        "            return str(result)\n",
        "        except Exception as e:\n",
        "            return f\"Error: {e}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "gj04803kXMSy"
      },
      "outputs": [],
      "source": [
        "from langchain.tools import tool\n",
        "\n",
        "@tool\n",
        "def calculator(expression: str) -> str:\n",
        "    \"\"\"\n",
        "    Perform arithmetic calculations.\n",
        "    Input: A mathematical expression as a string (e.g., \"2 + 2\").\n",
        "    Output: Result of the calculation as a string.\n",
        "    \"\"\"\n",
        "    calc = Calculator()\n",
        "    return calc.calculate(expression)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "XjUVVuwQXQrl"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import GoogleGenerativeAI\n",
        "\n",
        "# Khởi tạo mô hình với API key và model hiện hành (\"gemini-pro\" hay tên model tương ứng)\n",
        "llm = GoogleGenerativeAI(model=\"gemini-pro\", api_key=GOOGLE_GENERATIVE_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "ekZcrqaNXc2m"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import GoogleGenerativeAI\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.tools import Tool\n",
        "\n",
        "# Khởi tạo mô hình Gemini-Pro với API Key\n",
        "llm = GoogleGenerativeAI(model=\"gemini-1.5-pro-latest\", api_key=GOOGLE_GENERATIVE_API_KEY)\n",
        "\n",
        "# Tạo công cụ cho agent\n",
        "tools = [calculator]\n",
        "\n",
        "# Khởi tạo Agent với mô hình Gemini-Pro\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,  # Chọn loại Agent phù hợp\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Thực thi Agent\n",
        "executor = agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "_D43NVeBZ55G"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Khởi tạo bộ nhớ hội thoại\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "# Tạo PromptTemplate cho hội thoại\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"chat_history\", \"input\"],\n",
        "    template=\"Lịch sử hội thoại: {chat_history}\\nNgười dùng: {input}\\nTrả lời:\"\n",
        ")\n",
        "\n",
        "# Khởi tạo LLMChain\n",
        "chain = LLMChain(\n",
        "    llm=llm,\n",
        "    prompt=prompt,\n",
        "    memory=memory,\n",
        "    verbose=True  # Hiển thị log quá trình chạy\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhwLTQxQbyuq",
        "outputId": "d428c59f-6926-48db-8708-2202e2bcf3f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mLịch sử hội thoại: []\n",
            "Người dùng: What is 15 divided by 3?\n",
            "Trả lời:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "15 divided by 3 is 5.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "query = \"What is 15 divided by 3?\"\n",
        "response = chain.run(query)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyQS2JCqDjvw",
        "outputId": "099cf366-c885-475a-bb80-8008e3b1fc8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query: What is 25 multiplied by 4?\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mLịch sử hội thoại: [HumanMessage(content='What is 15 divided by 3?', additional_kwargs={}, response_metadata={}), AIMessage(content='15 divided by 3 is 5.\\n', additional_kwargs={}, response_metadata={})]\n",
            "Người dùng: What is 25 multiplied by 4?\n",
            "Trả lời:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Response: 25 multiplied by 4 is 100.\n",
            "\n",
            "----------------------------------------\n",
            "Query: Now divide the result by 5.\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mLịch sử hội thoại: [HumanMessage(content='What is 15 divided by 3?', additional_kwargs={}, response_metadata={}), AIMessage(content='15 divided by 3 is 5.\\n', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is 25 multiplied by 4?', additional_kwargs={}, response_metadata={}), AIMessage(content='25 multiplied by 4 is 100.\\n', additional_kwargs={}, response_metadata={})]\n",
            "Người dùng: Now divide the result by 5.\n",
            "Trả lời:\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain_core.language_models.llms:Retrying langchain_google_genai.llms._completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Response: 100 divided by 5 is 20.\n",
            "\n",
            "----------------------------------------\n",
            "Query: Add 10 to that.\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mLịch sử hội thoại: [HumanMessage(content='What is 15 divided by 3?', additional_kwargs={}, response_metadata={}), AIMessage(content='15 divided by 3 is 5.\\n', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is 25 multiplied by 4?', additional_kwargs={}, response_metadata={}), AIMessage(content='25 multiplied by 4 is 100.\\n', additional_kwargs={}, response_metadata={}), HumanMessage(content='Now divide the result by 5.', additional_kwargs={}, response_metadata={}), AIMessage(content='100 divided by 5 is 20.\\n', additional_kwargs={}, response_metadata={})]\n",
            "Người dùng: Add 10 to that.\n",
            "Trả lời:\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain_core.language_models.llms:Retrying langchain_google_genai.llms._completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "WARNING:langchain_core.language_models.llms:Retrying langchain_google_genai.llms._completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "WARNING:langchain_core.language_models.llms:Retrying langchain_google_genai.llms._completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "WARNING:langchain_core.language_models.llms:Retrying langchain_google_genai.llms._completion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Response: 20 + 10 is 30.\n",
            "\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "queries = [\n",
        "    \"What is 25 multiplied by 4?\",\n",
        "    \"Now divide the result by 5.\",\n",
        "    \"Add 10 to that.\"\n",
        "]\n",
        "\n",
        "for q in queries:\n",
        "    print(\"Query:\", q)\n",
        "    print(\"Response:\", chain.run(q))\n",
        "    print(\"-\" * 40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2vN3u6ZDyEB",
        "outputId": "54118be8-0799-4e72-9338-fd53f4e3c673"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mLịch sử hội thoại: [HumanMessage(content='What is 15 divided by 3?', additional_kwargs={}, response_metadata={}), AIMessage(content='15 divided by 3 is 5.\\n', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is 25 multiplied by 4?', additional_kwargs={}, response_metadata={}), AIMessage(content='25 multiplied by 4 is 100.\\n', additional_kwargs={}, response_metadata={}), HumanMessage(content='Now divide the result by 5.', additional_kwargs={}, response_metadata={}), AIMessage(content='100 divided by 5 is 20.\\n', additional_kwargs={}, response_metadata={}), HumanMessage(content='Add 10 to that.', additional_kwargs={}, response_metadata={}), AIMessage(content='20 + 10 is 30.\\n', additional_kwargs={}, response_metadata={})]\n",
            "Người dùng: What is LangChain Function?\n",
            "Trả lời:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "LangChain is a framework designed to simplify the development of applications using large language models (LLMs). It provides a standard interface and abstractions for common LLM tasks, allowing developers to connect LLMs to other data sources and integrate them with different tools.  Think of it as a toolbox specifically built for working with LLMs.\n",
            "\n",
            "Here's a breakdown of its key functions and features:\n",
            "\n",
            "* **Chains:**  This is the core concept.  Chains allow you to combine multiple components together to create a sequence of operations. For example, you could create a chain that first gets relevant information from a search engine, then summarizes it using an LLM, and finally translates the summary into a different language.  These chains can be simple or complex, depending on the task.\n",
            "\n",
            "* **Components:** These are the building blocks of chains.  They include LLMs, prompts, agents, memory, indexes, and other tools.  LangChain provides a wide range of pre-built components, and you can also create your own custom components.\n",
            "\n",
            "* **Indexes:**  These help structure your data to make it easier for LLMs to access and process.  Different types of indexes are suitable for different data types, like documents, code, chat history, etc.  LangChain provides tools to create and manage these indexes.\n",
            "\n",
            "* **Agents:**  Agents enable LLMs to interact with their environment.  They can decide which actions to take, such as searching the web or accessing a database, based on the current context.  LangChain supports various agent frameworks.\n",
            "\n",
            "* **Memory:**  Memory allows chains and agents to retain information from previous interactions.  This is essential for building conversational applications and maintaining context over time.  LangChain provides different memory implementations.\n",
            "\n",
            "* **Callbacks:**  Callbacks provide a mechanism to monitor and log the execution of chains and agents.  This is helpful for debugging and understanding how your application is working.\n",
            "\n",
            "In essence, LangChain helps you build more complex and powerful LLM applications by providing:\n",
            "\n",
            "* **Modularity:** Easily combine different components and swap them out as needed.\n",
            "* **Flexibility:**  Connect to various LLMs, data sources, and tools.\n",
            "* **Abstraction:**  Simplify complex LLM interactions with easy-to-use interfaces.\n",
            "* **Extensibility:**  Create custom components and adapt to evolving LLM capabilities.\n",
            "\n",
            "\n",
            "So, instead of writing custom code for each LLM task, you can use LangChain to assemble pre-built components and create sophisticated applications more efficiently.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "query = \"What is LangChain Function?\"\n",
        "response = chain.run(query)\n",
        "print(response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
